import pandas as pd
from sklearn.model_selection import cross_validate, train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.compose import ColumnTransformer, make_column_transformer
from sklearn.linear_model import LogisticRegression
import matplotlib.pyplot as plt


# loading dataset into a readable dataframe
car_table = pd.read_csv('data/car.data', sep = ",", header=None, names = ["price", "maint", "doors", "persons", "lug_boot", "safety", "class"],)
car_table.style.set_caption('Table 1')
car_table


# checks to see if there are any nulls/nan values in the dataframe
car_table.isnull().values.any()


price = pd.DataFrame(car_table["price"])

# price.value_counts().plot(kind='bar')
plt.hist(price, bins=7)
plt.xlabel("Price")
plt.ylabel("Count")
plt.title("Figure 1: Distribution of Price Variable")
plt.figure(figsize=(15, 12), dpi= 80)


# categorizing features(price, maint, doors, persons, lug_boot, safety, class) to be used a in column transformer to enable easy manipulation of data frame

ordinal_feats = ["price", "maint", "doors", "persons", "lug_boot", "safety", "class"]

# categories of each feature
maint_levels = ['low', 'med', 'high', 'vhigh']
doors_levels = ['2', '3', '4', '5more']
persons_levels = ['2', '4', 'more']
boot_levels = ['small', 'med', 'big']
safety_levels = ['low', 'med', 'high']
class_levels = ['unacc', 'acc', 'good', 'vgood']


# ordinal encoding of each feature
column_transformer = make_column_transformer(
    (OrdinalEncoder(categories=[maint_levels, maint_levels, doors_levels, persons_levels, boot_levels, safety_levels, class_levels],
                    dtype = int),
                    ordinal_feats)
)

X_transformed = column_transformer.fit_transform(car_table)
column_names = (ordinal_feats)




# creating new table after data preprcoessing 
new_table = pd.DataFrame(X_transformed, columns=column_names)

# splitting of target variable and features
X_car = new_table.drop(columns=["price"])
Y_car = new_table['price']


# splitting of data frame into training and testing data
X_train, X_Test, y_train, y_test = train_test_split(X_car, Y_car, test_size=0.2, random_state=1)

# features used for modeling
feats = ["maint", "doors", "persons", "lug_boot", "safety", "class"]


#' Dataframe of dependent variables
#'
#' Creates a new data frame with the given targetValue
#'
#' @param data_frame A data frame or data frame extension (e.g. a tibble).
#' @param target_Value column containing the dependent variable
#'
#' @return A data frame with the given target_Value. 
#'   The first column (named target_Value) lists the possible outputs for the given variable.
#'
#' @examples depedent_Values(car_table, doors)

def dependent_Values(data_frame, target_Value):
    print(target_Value)
    # return a data frame from with one column: targetValue


# fitting model for classification analysis

lr = LogisticRegression(max_iter=1000, C=100)
lr.fit(X_train, y_train)

coeffs = lr.coef_[3]

score = cross_validate(lr, X_Test, y_test, cv=10)

pd.DataFrame(score)



# coefficients of each feature


data = {"features":feats, "coefficient":coeffs}
df1 = pd.DataFrame(data).sort_values(by=['coefficient'])
pd.DataFrame(data)



df1 = df1.sort_values(by=['coefficient'])

fig2 = plt.figure()
axes = fig2.add_axes([0,0,1,1])
axes.set_title('Figure 2: Graph of training coefficients')
axes.set_xlabel('Features')
axes.set_ylabel('Coefficient Values')

axes.bar(df1['features'][:2], df1['coefficient'][:2], color="red")
axes.bar(df1['features'][2:], df1['coefficient'][2:])
plt.show()
